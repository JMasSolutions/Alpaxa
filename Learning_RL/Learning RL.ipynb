{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "287f97a07a8179f4",
   "metadata": {},
   "source": [
    "# 1.Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import os\n",
    "import gymnasium\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b32de1e03af6a0b9",
   "metadata": {},
   "source": [
    "# 2. Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "id": "ec3f639f5d95cd91",
   "metadata": {},
   "source": [
    "environment_name = 'CartPole-v1'\n",
    "env = gymnasium.make(environment_name, render_mode=\"human\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d514f166f9c4f84",
   "metadata": {},
   "source": [
    "# episodes = 5\n",
    "# for episode in range(1, episodes + 1):\n",
    "#     state = env.reset()\n",
    "#     done = False\n",
    "#     score = 0\n",
    "# \n",
    "#     while not done:\n",
    "#         action = env.action_space.sample()\n",
    "#         n_state, reward, terminated, truncated, info = env.step(action)\n",
    "#         done = terminated or truncated\n",
    "#         score += reward\n",
    "# \n",
    "#     print(f'Episode:{episode}, Score:{score}')\n",
    "# env.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b41950eaed66cb00",
   "metadata": {},
   "source": [
    "# 3.Understanding the Environment"
   ]
  },
  {
   "cell_type": "code",
   "id": "5208f8ca5bee630b",
   "metadata": {},
   "source": [
    "env.action_space"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "49b3825a5bc85dbf",
   "metadata": {},
   "source": [
    "env.action_space.sample()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "887f511dabe68de1",
   "metadata": {},
   "source": [
    "env.observation_space.sample()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dc0acaa3c16162ab",
   "metadata": {},
   "source": [
    "# 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "9ff51ba4c8167df1",
   "metadata": {},
   "source": [
    "log_path = os.path.join('Training', 'Logs')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8465188f29dab0c7",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS is not available, using CPU.\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7372fca2c8e99cb1",
   "metadata": {},
   "source": [
    "env = gymnasium.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path, device=device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9e0066099b1dd138",
   "metadata": {},
   "source": [
    "model.learn(total_timesteps=20000)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f5fe05b6eaf35118",
   "metadata": {},
   "source": [
    "# 5. Save Model & Load Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "40778161c891ca5d",
   "metadata": {},
   "source": [
    "PPO_path = os.path.join('Training', 'Saved Models', 'PPO_model_CartPole')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3cd944054becb133",
   "metadata": {},
   "source": [
    "model.save(PPO_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f57aa76107431949",
   "metadata": {},
   "source": [
    "del model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d74dd9f4f1e8b8cd",
   "metadata": {},
   "source": [
    "model = PPO.load(PPO_path, env=env)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8ded61735ea84195",
   "metadata": {},
   "source": [
    "# 6. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "id": "9f3337fb9f45288d",
   "metadata": {},
   "source": [
    "# Step 1: Recreate the environment\n",
    "env = gymnasium.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "\n",
    "# Step 2: Define the path to the saved model\n",
    "PPO_path = os.path.join(\"Training\", \"Saved Models\", \"PPO_model_CartPole\")\n",
    "\n",
    "# Step 3: Load the saved model\n",
    "model = PPO.load(PPO_path, env=env)\n",
    "\n",
    "# Step 4: Custom evaluation function\n",
    "def evaluate_policy_with_rendering(model, env, n_eval_episodes=10, render=True):\n",
    "    \"\"\"\n",
    "    Evaluate the policy of a loaded model with optional rendering.\n",
    "    \"\"\"\n",
    "    episode_rewards = []\n",
    "\n",
    "    for episode in range(n_eval_episodes):\n",
    "        reset_output = env.reset()\n",
    "        state = reset_output[0] if isinstance(reset_output, tuple) else reset_output\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            if render:\n",
    "                env.render()  # Render each frame\n",
    "\n",
    "            # Get the action from the model\n",
    "            action, _states = model.predict(state, deterministic=True)\n",
    "            \n",
    "            # Adjust for environments returning 4 or 5 values\n",
    "            step_output = env.step(action)\n",
    "            if len(step_output) == 5:\n",
    "                state, reward, terminated, truncated, info = step_output\n",
    "            else:\n",
    "                state, reward, terminated, truncated = step_output\n",
    "\n",
    "            # Convert reward to scalar to avoid warnings\n",
    "            total_reward += reward.item() if hasattr(reward, 'item') else float(reward)\n",
    "\n",
    "            # Combine termination flags\n",
    "            done = terminated or truncated\n",
    "\n",
    "        episode_rewards.append(total_reward)\n",
    "        print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "\n",
    "    # Calculate mean and standard deviation of rewards\n",
    "    mean_reward = sum(episode_rewards) / n_eval_episodes\n",
    "    std_reward = (sum([(x - mean_reward) ** 2 for x in episode_rewards]) / n_eval_episodes) ** 0.5\n",
    "\n",
    "    return mean_reward, std_reward\n",
    "\n",
    "# Step 5: Evaluate the loaded model\n",
    "mean_reward, std_reward = evaluate_policy_with_rendering(model, env, n_eval_episodes=10, render=True)\n",
    "print(f\"Mean reward: {mean_reward}, Std reward: {std_reward}\")\n",
    "\n",
    "# Close the environment\n",
    "env.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7. Test Model",
   "id": "6a10388191b973ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "\n",
    "# Define the path to the saved model\n",
    "PPO_path = os.path.join(\"Training\", \"Saved Models\", \"PPO_model_CartPole\")\n",
    "\n",
    "# Load the saved model\n",
    "model = PPO.load(PPO_path, env=env)\n",
    "\n",
    "# Number of episodes\n",
    "episodes = 10\n",
    "\n",
    "for episode in range(1, episodes + 1):\n",
    "    # Extract the observation from the reset output\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        score += reward\n",
    "\n",
    "    print(f'Episode: {episode}, Score: {score}')\n",
    "\n",
    "# Close the environment\n",
    "env.close()"
   ],
   "id": "35c135133af76057",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 8. View Logs in Tensorboard",
   "id": "9767a95fde3ce94d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T04:47:59.084983Z",
     "start_time": "2024-12-20T04:47:59.082216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "log_path = os.path.join('Training', 'Logs')\n",
    "training_log_path = os.path.join(log_path, 'PPO_2')\n"
   ],
   "id": "945a408411a8b8d3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T04:50:45.684150Z",
     "start_time": "2024-12-20T04:48:21.624766Z"
    }
   },
   "cell_type": "code",
   "source": "!tensorboard --logdir={training_log_path}",
   "id": "2b6436bd504b63a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\r\n",
      "TensorBoard 2.18.0 at http://localhost:6006/ (Press CTRL+C to quit)\r\n",
      "W1220 12:48:48.656814 6127382528 application.py:559] path /apple-touch-icon-precomposed.png not found, sending 404\r\n",
      "W1220 12:48:48.712542 6127382528 application.py:559] path /apple-touch-icon.png not found, sending 404\r\n",
      "^C\r\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
